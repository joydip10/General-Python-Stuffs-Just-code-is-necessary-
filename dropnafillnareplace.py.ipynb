{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF\n",
      "             Event  Temperature  Windspeed\n",
      "Date                                      \n",
      "2017-01-01   Rainy    23.000000   6.000000\n",
      "2017-02-01   Sunny    22.000000   3.376652\n",
      "2017-03-01   Sunny    24.115532   4.000000\n",
      "2017-04-01  Cloudy    26.000000        NaN\n",
      "2017-05-01     NaN          NaN        NaN\n",
      "2017-06-01     NaN          NaN        NaN\n",
      "2017-07-01   Sunny    23.151988   5.205661\n",
      "2017-08-01   Rainy    24.000000   4.741296\n",
      "2017-09-01     NaN          NaN        NaN\n",
      "2017-10-01   Clear    25.000000   6.000000\n",
      "DF\n",
      "             Event  Temperature  Windspeed\n",
      "Date                                      \n",
      "2017-01-01   Rainy    23.000000   6.000000\n",
      "2017-02-01   Sunny    22.000000   3.376652\n",
      "2017-03-01   Sunny    24.115532   4.000000\n",
      "2017-04-01  Cloudy    26.000000        NaN\n",
      "2017-07-01   Sunny    23.151988   5.205661\n",
      "2017-08-01   Rainy    24.000000   4.741296\n",
      "2017-10-01   Clear    25.000000   6.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOY STARK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Windspeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.376652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>24.115532</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>Cloudy</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>23.151988</td>\n",
       "      <td>5.205661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.741296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>Clear</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Event  Temperature  Windspeed\n",
       "Date                                      \n",
       "2017-01-01   Rainy    23.000000   6.000000\n",
       "2017-02-01   Sunny    22.000000   3.376652\n",
       "2017-03-01   Sunny    24.115532   4.000000\n",
       "2017-04-01  Cloudy    26.000000        NaN\n",
       "2017-05-01     NaN          NaN        NaN\n",
       "2017-06-01     NaN          NaN        NaN\n",
       "2017-07-01   Sunny    23.151988   5.205661\n",
       "2017-08-01   Rainy    24.000000   4.741296\n",
       "2017-09-01     NaN          NaN        NaN\n",
       "2017-10-01   Clear    25.000000   6.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "weather={\n",
    "    'Date':['1/1/2017','2/1/2017','3/1/2017','4/1/2017','5/1/2017','6/1/2017','7/1/2017','8/1/2017','9/1/2017','10/1/2017'],\n",
    "    'Event':['Rainy','Sunny','Sunny','Cloudy','','','Sunny','Rainy','','Clear'],\n",
    "    'Temperature':[23,22,'',26,24,23,'',24,25,25],\n",
    "    'Windspeed':[6,'',4,7,7,6,'','',5,6]\n",
    "}\n",
    "df=pd.DataFrame(weather)\n",
    "df.to_csv(r'C:\\Users\\JOY STARK\\Desktop\\Datasets\\weather\\missing_value.csv',index=False,columns=['Date','Event','Temperature','Windspeed'])\n",
    "df=pd.read_csv(r'C:\\Users\\JOY STARK\\Desktop\\Datasets\\weather\\missing_value.csv',na_values=[''],parse_dates=['Date'])\n",
    "df.set_index('Date',inplace=True)\n",
    "#df=df.fillna(0)\n",
    "#df=df.fillna({\n",
    "#    'Event':'no event',\n",
    "#    'Temperature':0,\n",
    "#    'Windspeed':0\n",
    "#})\n",
    "#df=df.fillna(method='ffill')\n",
    "#df=df.fillna(method='bfill',axis='rows',limit=2)#we can use limit option to choose how many times we want to copy the data\n",
    "df=df.interpolate(method='quadratic')#uses interpolation method to guess the values\n",
    "df_droppedna=df.dropna() #we can use method='all' or thresh=1/others to consider one or more null values\n",
    "#dt=pd.date_range('2017-01-01','2017-01-15')\n",
    "#idx=pd.DatetimeIndex(dt)\n",
    "#df=df.reindex(idx)\n",
    "df.fillna(0,inplace=True)\n",
    "df[:][df['Event']==0]=0\n",
    "df['Windspeed'][df['Event']=='Cloudy']=0\n",
    "r,c=df.shape\n",
    "l=list()\n",
    "count=0\n",
    "\n",
    "for i in range(r):\n",
    "     count=0\n",
    "     for j in range(c):\n",
    "            if df.iloc[i][j]==0:\n",
    "                count+=1\n",
    "     if(count>0):\n",
    "        if ((count/j)*100)>50:\n",
    "            l.append(i)\n",
    "\n",
    "\n",
    "            \n",
    "#df.drop([4,5,8],axis=1)\n",
    "df=df.replace({\n",
    "    'Event':0,\n",
    "    'Temperature':0,\n",
    "    'Windspeed':0\n",
    "},np.NaN)\n",
    "print('DF')\n",
    "print(df)\n",
    "\n",
    "print('DF')\n",
    "print(df.dropna(thresh=2))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Event'][df['Temperature']>23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=df.groupby('Event')\n",
    "g.get_group('Sunny')[['Temperature','Windspeed']].max()\n",
    "g['Temperature'].max()\n",
    "g.describe()\n",
    "%matplotlib inline\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event,event_df in g:\n",
    "    print(event)\n",
    "    print(event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.get_group('Sunny').replace({\n",
    "    'Temperature':'[A-Za-z]',\n",
    "    'Windspeed':['A-Za-z']\n",
    "},'',regex=True)['Temperature'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a=pd.DataFrame({\n",
    "    'City':['Dhaka','Chittagong','Sylhet'],\n",
    "    'Temperature':[23,25,24],\n",
    "    'Humidity':[85.5,82.5,83.5]\n",
    "})\n",
    "b=pd.DataFrame({\n",
    "    'City':['New York','San Fransisco','Los Angels'],\n",
    "    'Temperature':[15,10,5],\n",
    "    'Humidity':[45.5,24.5,15.5]\n",
    "})\n",
    "a.set_index('City')\n",
    "b.set_index('City')\n",
    "d=pd.concat([a,b],axis=1,keys=['Bangladesh','New York'])\n",
    "c=pd.DataFrame({\n",
    "    'City':['Dhaka','Chittagong','Sylhet'],\n",
    "    'Temperature':[23,25,24],\n",
    "},index=[0,1,2])\n",
    "e=pd.DataFrame({\n",
    "    'City':['Dhaka','Sylhet','Chittagong'],\n",
    "    'Humidity':[45.5,24.5,15.5]\n",
    "},index=[0,2,1])\n",
    "ce_concat=pd.concat([c,e],axis=1,keys=['temperature','humidity'])\n",
    "ser=pd.Series(['humid','Dry','Rainy'],name='Event')\n",
    "serr=pd.concat([c,ser],axis=1,ignore_index=False)\n",
    "ce_merge=pd.merge(c,e,on='City')\n",
    "ce_merge\n",
    "stock1=pd.DataFrame({\n",
    "    'Date':['1/1/2020','2/1/2020','3/1/2020'],\n",
    "    'stock1':[85.5,82.5,83.5]\n",
    "})\n",
    "stock2=pd.DataFrame({\n",
    "    'Date':['1/1/2020','2/1/2020','5/1/2020'],\n",
    "    'stock2':[82.5,79.5,89.5]\n",
    "})\n",
    "#stock_concat=pd.concat([stock1,stock2],axis=1,ignore_index=True)\n",
    "stock_concat=pd.concat([stock1,stock2],axis=0,keys=['stock1','stock2'],sort=True)\n",
    "stock_concat\n",
    "stock_merge=pd.merge(stock1,stock2,on='Date',how='outer')#indicator=True,suffixes='merge'\n",
    "stock_merge.Date=pd.to_datetime(stock_merge.Date)\n",
    "stock_merge.set_index('Date')\n",
    "stock_merge.dropna(thresh=1)\n",
    "stock_concat.columns.names=['Stock_names']\n",
    "stock_concat.xs(key='stock1',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=pd.Series(['Hot','Humid','Cool'],name='Events')\n",
    "p=pd.concat([c,l],axis=1)\n",
    "p.pivot(index='City',columns='Temperature',values='Events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b3bc6c0da8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#pivot table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m data=pd.DataFrame({\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;34m'Date'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'5/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'7/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'8/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'10/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'7/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'8/1/20'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'9/1/20'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'City'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'New York'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'New York'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'New York'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'New York'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'New York'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Mumbai'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Mumbai'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Mumbai'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Mumbai'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Mumbai'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'Temperature'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#pivot table\n",
    "data=pd.DataFrame({\n",
    "    'Date':['5/1/20','6/1/20','7/1/20','8/1/20','10/1/20','5/1/20','6/1/20','7/1/20','8/1/20','9/1/20'],\n",
    "    'City':['New York','New York','New York','New York','New York','Mumbai','Mumbai','Mumbai','Mumbai','Mumbai'],\n",
    "    'Temperature':[23,24,26,25,23,22,21,25,27,21],\n",
    "    'Humidity':[84.6,82.6,86.6,82.6,88.6,86.6,84.6,83.6,82.6,81.6]\n",
    "})\n",
    "data.Date=pd.to_datetime(data.Date)\n",
    "data_pivot=data.pivot(index='Date',columns='City',values=['Temperature','Humidity'])\n",
    "data_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.DataFrame({\n",
    "    'Date':['5/1/20','5/1/20','6/1/20','10/1/20','5/1/20','5/1/20','6/1/20','6/1/20'],\n",
    "    'City':['New York','New York','New York','New York','Mumbai','Mumbai','Mumbai','Mumbai'],\n",
    "    'Temperature':[23,24,23,22,21,25,27,21],\n",
    "    'Humidity':[84.6,82.6,88.6,86.6,84.6,83.6,82.6,81.6]\n",
    "})\n",
    "data1_pivottable=data1.pivot_table(index='Date',columns='City',values=['Temperature','Humidity'],aggfunc='mean',margins=True)\n",
    "data1_pivottable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.DataFrame({\n",
    "    'Date':['5/1/20','6/3/20','5/6/20','8/2/20','8/1/20'],\n",
    "    'City':['New York','New York','New York','New York','New York'],\n",
    "    'Temperature':[23,24,26,25,23],\n",
    "    'Humidity':[84.6,82.6,86.6,82.6,88.6]\n",
    "})\n",
    "data2.Date=pd.to_datetime(data2.Date)\n",
    "data2_pivottable=data2.pivot_table(index='Date',columns='City')\n",
    "data2_pivottable=data2.pivot_table(index=pd.Grouper(freq='M',key='Date'),columns='City')\n",
    "data2_pivottable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt\n",
    "dataformelt=pd.DataFrame({\n",
    "    'day':['Sunday','Monday','Tuesday','Wednessday','Thrusday','Friday','Saturday'],\n",
    "    'stock1':[23,25,24,26,24,21,54],\n",
    "    'stock2':[22,21,26,23,27,21,56],\n",
    "    'stock3':[20,21,29,28,31,34,23]\n",
    "})\n",
    "dataformelt_bymelt=pd.melt(dataformelt,id_vars='day',var_name='Stocks',value_name='Price')\n",
    "dataformelt_bymelt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataformelt[['day','stock1']][dataformelt['stock1']==dataformelt['stock1'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl=pd.DataFrame({\n",
    "    'name':['John','Joy','Samin','Kashpiya','Volgertz'],\n",
    "    'age':[25,23,23,22,24],\n",
    "    'nationality':['England','Bangladesh','India','Dubai','Russia'],\n",
    "    'handedness':['Left','Right','Left','Right','Right']\n",
    "})\n",
    "g=rl.groupby('handedness')\n",
    "#for group_name,group_object in g:\n",
    "#    print(group_name)\n",
    "#    print(group_object)                         \n",
    "#    print('\\n')\n",
    "k=g.get_group('Right')\n",
    "k.loc[:,['name','nationality']][k['age']==k['age'].max()]\n",
    "pd.crosstab([rl.handedness,rl.nationality],rl.age,normalize='index')\n",
    "pd.crosstab([rl.handedness,rl.nationality],rl.age,margins='all')\n",
    "\n",
    "pd.crosstab(rl.nationality,rl.handedness,values=rl.age,aggfunc=np.average,margins='all')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
